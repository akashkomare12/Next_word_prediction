{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "J1D42emD32Ro"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries from TensorFlow and Keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KhtDxwL_AXFj"
   },
   "outputs": [],
   "source": [
    "# 1. Tokenization and sequence processing\n",
    "\n",
    "# Initialize the tokenizer for processing text data\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IrmA3eaj3kF0"
   },
   "outputs": [],
   "source": [
    "with open('../../datasets/traindata.txt', 'r', encoding='utf-8') as file:\n",
    "    faqs = file.read()# read the text from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "K8MRFre9AaG9"
   },
   "outputs": [],
   "source": [
    "# Fit the tokenizer on the text data to create a vocabulary\n",
    "tokenizer.fit_on_texts([faqs])   \n",
    "\n",
    "# Define vocabulary size by adding 1 to the word index length (for padding)\n",
    "vocab_size = len(tokenizer.word_index) + 1 # Add 1 for padding token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YrpAl3EDAgvh",
    "outputId": "cabe3c83-7274-4512-94d5-b5def2b72453"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "282"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "44VahqKdAjr9"
   },
   "outputs": [],
   "source": [
    "# Generate input sequences\n",
    "\n",
    "input_sequences = []\n",
    "for sentence in faqs.split('\\n'):\n",
    "    # Convert each sentence to a sequence of tokens\n",
    "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "    \n",
    "    # Generate n-gram sequences (increasing subsets of the sentence) for training\n",
    "    for i in range(1,len(tokenized_sentence)):\n",
    "        input_sequences.append(tokenized_sentence[:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UyqwPDzNA5mR",
    "outputId": "98e99353-46c5-4252-c280-85f8eeef1dec"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CrzbvUUQCXPU"
   },
   "outputs": [],
   "source": [
    "# Determine the maximum length of sequences for padding consistency\n",
    "max_len = max([len(x) for x in input_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9oPMoWBSD1_U"
   },
   "outputs": [],
   "source": [
    "# Pad sequences to ensure they are the same length\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "miRb-QZyIi7_",
    "outputId": "de5c2b4e-b6e6-4e4b-a892-f97eff72c1c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,  93,   1],\n",
       "       [  0,   0,   0, ...,  93,   1,  13],\n",
       "       [  0,   0,   0, ...,   0,  11,   7],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 279,  18, 280],\n",
       "       [  0,   0,   0, ...,  18, 280, 281],\n",
       "       [  0,   0,   0, ..., 280, 281, 282]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qVI0-UUrIsd3"
   },
   "outputs": [],
   "source": [
    "# Split data into predictors (X) and target labels (y)\n",
    "X = padded_input_sequences[:,:-1]    # X consists of the sequence without the last token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "lXrYHTDFI3uE"
   },
   "outputs": [],
   "source": [
    "y = padded_input_sequences[:,-1]     # y is the last token in each sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kmsFnHx1Qdow",
    "outputId": "38cc3392-f099-49e2-f0c9-52955380d43e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(863, 56)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-wyYqYgZSeck",
    "outputId": "5c223cc0-a8e9-4c4f-a364-a436bc492abf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(863,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OL3vrEXSs_s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rs1NPitwSgzk"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "# Convert target labels to one-hot encoded vectors for categorical prediction\n",
    "y = to_categorical(y,num_classes=283)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQMJ0I6xSiZf",
    "outputId": "bba7b827-0696-427e-9d3d-c811600ce5a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((863, 56), (863, 283))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9kVeTvR2S8Fk"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "wo-OYfHpTK2o"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKASH\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 2. Model Building\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "#Embedding layer to learn word embeddings from input tokens\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=100, input_length=X.shape[1]))\n",
    "\n",
    "# First LSTM layer with return_sequences=True to pass the output to the next LSTM\n",
    "model.add(LSTM(150, return_sequences=True)) \n",
    "\n",
    "# Second LSTM layer without return_sequences to pass a single output vector to the Dense layer\n",
    "model.add(LSTM(150))   \n",
    "\n",
    "# Dense layer with softmax activation for next-word prediction across the vocabulary\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.build(input_shape=(None, max_len-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "-GGjqh7ue_Yq"
   },
   "outputs": [],
   "source": [
    "# 3. Compile and Train the Model\n",
    "# Compile the model using categorical crossentropy as the loss function and Adam optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxxXkrSXfIBv",
    "outputId": "d809aa2b-600f-4549-cfc1-1dfd1fef1a27"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">28,300</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">180,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">283</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">42,733</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │          \u001b[38;5;34m28,300\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m150\u001b[0m)             │         \u001b[38;5;34m150,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 │         \u001b[38;5;34m180,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m283\u001b[0m)                 │          \u001b[38;5;34m42,733\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">402,233</span> (1.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m402,233\u001b[0m (1.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">402,233</span> (1.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m402,233\u001b[0m (1.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LpFUCALCfJRR",
    "outputId": "96d67a78-3c2e-4462-b2a8-2655c303af8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2c9e89fc670>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on the prepared dataset for 100 epochs\n",
    "model.fit(X,y,epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGeYGwCMfTus",
    "outputId": "2d508555-b83e-470e-e7e5-1b5c10cce70b"
   },
   "outputs": [],
   "source": [
    "def WordPredict():\n",
    "    import time\n",
    "    text = input('Enter sentence : ')\n",
    "\n",
    "    for i in range(5):\n",
    "      # tokenize\n",
    "      token_text = tokenizer.texts_to_sequences([text])[0]\n",
    "      # padding\n",
    "      padded_token_text = pad_sequences([token_text], maxlen=56, padding='pre')\n",
    "      # predict\n",
    "      pos = np.argmax(model.predict(padded_token_text,  verbose=0))\n",
    "\n",
    "      for word,index in tokenizer.word_index.items():\n",
    "        if index == pos:\n",
    "          text = text + \" \" + word\n",
    "    print('Output : ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "92y7gE6pj9EZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter sentence : monthly payments\n",
      "Output :  monthly payments sessions are 2 hours so\n",
      "\n",
      "Enter sentence : subscription\n",
      "Output :  subscription registration related questions 2 criterias\n",
      "\n",
      "Enter sentence : How will I be informed about the upcoming class?\n",
      "Output :  How will I be informed about the upcoming class? part of this program what\n",
      "\n",
      "Enter sentence : Placement assistance\n",
      "Output :  Placement assistance outside india and i am\n",
      "\n",
      "Enter sentence : contact\n",
      "Output :  contact and placement related queries strategies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    WordPredict()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
